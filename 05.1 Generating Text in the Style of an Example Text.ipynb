{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "colab_type": "code",
    "id": "PGLS_ZOe5Vnf",
    "outputId": "a5e28892-fe31-4331-dd6d-d2a7a96b4521"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "Suggested packages:\n",
      "  db5.3-doc\n",
      "The following NEW packages will be installed:\n",
      "  libdb5.3-dev\n",
      "0 upgraded, 1 newly installed, 0 to remove and 8 not upgraded.\n",
      "Need to get 762 kB of archives.\n",
      "After this operation, 3,146 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libdb5.3-dev amd64 5.3.28-13.1ubuntu1 [762 kB]\n",
      "Fetched 762 kB in 1s (1,091 kB/s)\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "dpkg-preconfigure: unable to re-open stdin: \n",
      "Selecting previously unselected package libdb5.3-dev.\n",
      "(Reading database ... 131284 files and directories currently installed.)\n",
      "Preparing to unpack .../libdb5.3-dev_5.3.28-13.1ubuntu1_amd64.deb ...\n",
      "Unpacking libdb5.3-dev (5.3.28-13.1ubuntu1) ...\n",
      "Setting up libdb5.3-dev (5.3.28-13.1ubuntu1) ...\n"
     ]
    }
   ],
   "source": [
    "!sudo apt install libdb5.3-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade setuptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 819
    },
    "colab_type": "code",
    "id": "tiCi2V2G3bUq",
    "outputId": "d6b02654-1cda-482c-bbd8-f380507eb408"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: setuptools in /usr/local/lib/python3.6/dist-packages (40.8.0)\n",
      "Collecting gutenberg\n",
      "  Downloading https://files.pythonhosted.org/packages/14/b1/6e99867c38e70d46366966a0a861c580377f38312cf9dbad38b82ed1823d/Gutenberg-0.7.0.tar.gz\n",
      "Collecting bsddb3>=6.1.0 (from gutenberg)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/fc/ebfbd4de236b493f9ece156f816c21df0ae87ccc22604c5f9b664efef1b9/bsddb3-6.2.6.tar.gz (239kB)\n",
      "\u001b[K    100% |████████████████████████████████| 245kB 7.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.6/dist-packages (from gutenberg) (0.16.0)\n",
      "Collecting rdflib-sqlalchemy>=0.3.8 (from gutenberg)\n",
      "  Downloading https://files.pythonhosted.org/packages/92/a2/bc580a51ac1f9680aa04da4b6e96d499903d6e606d2f78f02e73527799da/rdflib_sqlalchemy-0.3.8-py3-none-any.whl\n",
      "Collecting rdflib>=4.2.0 (from gutenberg)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/fe/630bacb652680f6d481b9febbb3e2c3869194a1a5fc3401a4a41195a2f8f/rdflib-4.2.2-py3-none-any.whl (344kB)\n",
      "\u001b[K    100% |████████████████████████████████| 348kB 25.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests>=2.5.1 in /usr/local/lib/python3.6/dist-packages (from gutenberg) (2.18.4)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from gutenberg) (40.8.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from gutenberg) (1.11.0)\n",
      "Requirement already satisfied: SQLAlchemy>=1.1.4 in /usr/local/lib/python3.6/dist-packages (from rdflib-sqlalchemy>=0.3.8->gutenberg) (1.2.18)\n",
      "Collecting alembic>=0.8.8 (from rdflib-sqlalchemy>=0.3.8->gutenberg)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/06/f1ae8393463c26f3dafa21eebac611088da02a26e1f1e23bd75fee2dbffe/alembic-1.0.7.tar.gz (1.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.0MB 20.6MB/s \n",
      "\u001b[?25hCollecting isodate (from rdflib>=4.2.0->gutenberg)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 18.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from rdflib>=4.2.0->gutenberg) (2.3.1)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.5.1->gutenberg) (2.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.5.1->gutenberg) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.5.1->gutenberg) (2018.11.29)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.5.1->gutenberg) (1.22)\n",
      "Collecting Mako (from alembic>=0.8.8->rdflib-sqlalchemy>=0.3.8->gutenberg)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/eb/f3/67579bb486517c0d49547f9697e36582cd19dafb5df9e687ed8e22de57fa/Mako-1.0.7.tar.gz (564kB)\n",
      "\u001b[K    100% |████████████████████████████████| 573kB 24.2MB/s \n",
      "\u001b[?25hCollecting python-editor>=0.3 (from alembic>=0.8.8->rdflib-sqlalchemy>=0.3.8->gutenberg)\n",
      "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from alembic>=0.8.8->rdflib-sqlalchemy>=0.3.8->gutenberg) (2.5.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from Mako->alembic>=0.8.8->rdflib-sqlalchemy>=0.3.8->gutenberg) (1.1.0)\n",
      "Building wheels for collected packages: gutenberg, bsddb3, alembic, Mako\n",
      "  Building wheel for gutenberg (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/8e/cd/75/4bc6f16541a1b7a69b02168da567695b2271c23ac4a0a0a453\n",
      "  Building wheel for bsddb3 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/11/b8/b3/fa84db10bf8c563e4ba1a72837a0946d123f12adb34b164bf5\n",
      "  Building wheel for alembic (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/f9/71/46/604b8a4f0a04b513f5799c974b556c1de19a70fde41d25672b\n",
      "  Building wheel for Mako (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/15/35/25/dbcb848832ccb1a4b4ad23f529badfd3bce9bf88017f7ca510\n",
      "Successfully built gutenberg bsddb3 alembic Mako\n",
      "Installing collected packages: bsddb3, isodate, rdflib, Mako, python-editor, alembic, rdflib-sqlalchemy, gutenberg\n",
      "Successfully installed Mako-1.0.7 alembic-1.0.7 bsddb3-6.2.6 gutenberg-0.7.0 isodate-0.6.0 python-editor-1.0.4 rdflib-4.2.2 rdflib-sqlalchemy-0.3.8\n"
     ]
    }
   ],
   "source": [
    "!pip install gutenberg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Using cached https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /home/super/anaconda3/envs/ML/lib/python3.6/site-packages (from keras) (1.0.7)\n",
      "Requirement already satisfied: pyyaml in /home/super/anaconda3/envs/ML/lib/python3.6/site-packages (from keras) (3.13)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/super/anaconda3/envs/ML/lib/python3.6/site-packages (from keras) (1.12.0)\n",
      "Requirement already satisfied: h5py in /home/super/anaconda3/envs/ML/lib/python3.6/site-packages (from keras) (2.9.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/super/anaconda3/envs/ML/lib/python3.6/site-packages (from keras) (1.0.9)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/super/anaconda3/envs/ML/lib/python3.6/site-packages (from keras) (1.16.1)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/super/anaconda3/envs/ML/lib/python3.6/site-packages (from keras) (1.2.1)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.2.4\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rU6lpK_33ayM",
    "outputId": "b2c6f354-ab2e-4396-b64d-40b8d07bbd8f"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    GUTENBERG = True\n",
    "    from gutenberg.acquire import load_etext\n",
    "    from gutenberg.query import get_etexts, get_metadata\n",
    "    from gutenberg.acquire import get_metadata_cache\n",
    "    from gutenberg.acquire.text import UnknownDownloadUriException\n",
    "    from gutenberg.cleanup import strip_headers\n",
    "    from gutenberg._domain_model.exceptions import CacheAlreadyExistsException\n",
    "except ImportError:\n",
    "    GUTENBERG = False\n",
    "    print('Gutenberg is not installed. See instructions at https://pypi.python.org/pypi/Gutenberg')\n",
    "from keras.models import Input, Model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "import keras.callbacks\n",
    "import keras.backend as K\n",
    "import scipy.misc\n",
    "import json\n",
    "\n",
    "import os, sys\n",
    "import re\n",
    "import PIL\n",
    "from PIL import ImageDraw\n",
    "\n",
    "from keras.optimizers import RMSprop\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.utils import get_file\n",
    "\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "try:\n",
    "    from io import BytesIO\n",
    "except ImportError:\n",
    "    from StringIO import StringIO as BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fnVGqiNJ3ayP"
   },
   "outputs": [],
   "source": [
    "if GUTENBERG:\n",
    "    cache = get_metadata_cache()\n",
    "    try:\n",
    "        cache.populate()\n",
    "    except CacheAlreadyExistsException:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 5916
    },
    "colab_type": "code",
    "id": "qz2ZG4om3ayR",
    "outputId": "3c2b6ae7-0a95-464e-ca9e-96737c4b51f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 The Complete Works of William Shakespeare\n",
      "10281 Antony's Address over the Body of Caesar\n",
      "From Julius Caesar\n",
      "1100 The First Part of Henry the Sixth\n",
      "1101 The Second Part of King Henry the Sixth\n",
      "10606 The Tragedie of Hamlet, Prince of Denmark\n",
      "A Study with the Text of the Folio of 1623\n",
      "1102 The Third Part of King Henry the Sixth\n",
      "1103 King Richard III\n",
      "1041 Shakespeare's Sonnets\n",
      "1104 The Comedy of Errors\n",
      "1105 The Sonnets\n",
      "1106 The Tragedy of Titus Andronicus\n",
      "1045 Venus and Adonis\n",
      "1107 The Taming of the Shrew\n",
      "1108 The Two Gentlemen of Verona\n",
      "1109 Love's Labour's Lost\n",
      "1110 King John\n",
      "1111 King Richard the Second\n"
     ]
    }
   ],
   "source": [
    "if GUTENBERG:\n",
    "    for text_id in get_etexts('author', 'Shakespeare, William'):\n",
    "        print(text_id, list(get_metadata('title', text_id))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "62MRcUxo3ayU",
    "outputId": "b6e3d53e-6708-47f7-c507-8350763c49ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5537603"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if GUTENBERG:\n",
    "    shakespeare = strip_headers(load_etext(100))\n",
    "else:\n",
    "    path = get_file('shakespeare', 'https://storage.googleapis.com/deep-learning-cookbook/100-0.txt')\n",
    "    shakespeare = open(path).read()\n",
    "training_text = shakespeare.split('\\nTHE END', 1)[-1]\n",
    "len(training_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "s0nqz37H3ayW",
    "outputId": "4803bdd8-6d9b-4c13-a79b-611a59d5b15a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = list(sorted(set(training_text)))\n",
    "char_to_idx = {ch: idx for idx, ch in enumerate(chars)}\n",
    "len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pIG2LwgW3ayY"
   },
   "outputs": [],
   "source": [
    "def char_rnn_model(num_chars, num_layers, num_nodes=512, dropout=0.1):\n",
    "    input = Input(shape=(None, num_chars), name='input')\n",
    "    prev = input\n",
    "    for i in range(num_layers):\n",
    "        lstm = LSTM(num_nodes, return_sequences=True, name='lstm_layer_%d' % (i + 1))(prev)\n",
    "        if dropout:\n",
    "            prev = Dropout(dropout)(lstm)\n",
    "        else:\n",
    "            prev = lstm\n",
    "    dense = TimeDistributed(Dense(num_chars, name='dense', activation='softmax'))(prev)\n",
    "    model = Model(inputs=[input], outputs=[dense])\n",
    "    optimizer = RMSprop(lr=0.01)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "id": "qzcioWym3ayb",
    "outputId": "00f1dcd9-2dc3-421a-d1c0-c0a6e1ccd9f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, None, 94)          0         \n",
      "_________________________________________________________________\n",
      "lstm_layer_1 (LSTM)          (None, None, 640)         1881600   \n",
      "_________________________________________________________________\n",
      "lstm_layer_2 (LSTM)          (None, None, 640)         3279360   \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, None, 94)          60254     \n",
      "=================================================================\n",
      "Total params: 5,221,214\n",
      "Trainable params: 5,221,214\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = char_rnn_model(len(chars), num_layers=2, num_nodes=640, dropout=0)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1071
    },
    "colab_type": "code",
    "id": "P6xWaArz3ayd",
    "outputId": "a592c63a-a849-4e61-ab9e-3664194d0fd3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 1., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 1., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 1., ..., 0., 0., 0.],\n",
       "         [0., 0., 1., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 1., ..., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 1., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 1., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 1., 0., 0.]]]),\n",
       " array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 1., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 1., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 0., 1., ..., 0., 0., 0.],\n",
       "         [0., 0., 1., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 1., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 0., 1., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 1., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 1., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHUNK_SIZE = 160\n",
    "\n",
    "def data_generator(all_text, char_to_idx, batch_size, chunk_size):\n",
    "    X = np.zeros((batch_size, chunk_size, len(char_to_idx)))\n",
    "    y = np.zeros((batch_size, chunk_size, len(char_to_idx)))\n",
    "    while True:\n",
    "        for row in range(batch_size):\n",
    "            idx = random.randrange(len(all_text) - chunk_size - 1)\n",
    "            chunk = np.zeros((chunk_size + 1, len(char_to_idx)))\n",
    "            for i in range(chunk_size + 1):\n",
    "                chunk[i, char_to_idx[all_text[idx + i]]] = 1\n",
    "            X[row, :, :] = chunk[:chunk_size]\n",
    "            y[row, :, :] = chunk[1:]\n",
    "        yield X, y\n",
    "\n",
    "next(data_generator(training_text, char_to_idx, 4, chunk_size=CHUNK_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "OfEsY1yS3ayf",
    "outputId": "5fdd0c0d-3eb9-4100-81d1-6108b393c313"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      " - 109s - loss: 2.9157 - acc: 0.2815\n",
      "Epoch 2/40\n",
      " - 105s - loss: 2.2030 - acc: 0.4714\n",
      "Epoch 3/40\n",
      " - 105s - loss: 2.1948 - acc: 0.4748\n",
      "Epoch 4/40\n",
      " - 105s - loss: 2.2376 - acc: 0.4662\n",
      "Epoch 5/40\n",
      " - 109s - loss: 2.8949 - acc: 0.2875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f23c0d989b0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early = keras.callbacks.EarlyStopping(monitor='loss',\n",
    "                              min_delta=0.03,\n",
    "                              patience=3,\n",
    "                              verbose=0, mode='auto')\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "model.fit_generator(\n",
    "    data_generator(training_text, char_to_idx, batch_size=BATCH_SIZE, chunk_size=CHUNK_SIZE),\n",
    "    epochs=40,\n",
    "    callbacks=[early,],\n",
    "    steps_per_epoch=2 * len(training_text) / (BATCH_SIZE * CHUNK_SIZE),\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jwHq27ck3ayi"
   },
   "outputs": [],
   "source": [
    "with open('zoo/06/shakespeare.json', 'w') as fout:\n",
    "    json.dump({\n",
    "        'chars': ''.join(chars),\n",
    "        'char_to_idx': char_to_idx,\n",
    "        'chunk_size': CHUNK_SIZE,\n",
    "    }, fout)\n",
    "model.save('zoo/06/shakespeare.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ffQ8tgF3ayj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    But this I know- they have demean'd themselves\n",
      "    Like men born to renown by life or death.\n",
      "    Three times did Richard make a lane to me,\n",
      "    And thrice #                                                                                                                                                                                                                                                                                                                                                                                                                \n"
     ]
    }
   ],
   "source": [
    "def generate_output(model, training_text, start_index=None, diversity=None, amount=400):\n",
    "    if start_index is None:\n",
    "        start_index = random.randint(0, len(training_text) - CHUNK_SIZE - 1)\n",
    "    generated = training_text[start_index: start_index + CHUNK_SIZE]\n",
    "    yield generated + '#'\n",
    "    for i in range(amount):\n",
    "        x = np.zeros((1, len(generated), len(chars)))\n",
    "        for t, char in enumerate(generated):\n",
    "            x[0, t, char_to_idx[char]] = 1.\n",
    "        preds = model.predict(x, verbose=0)[0]\n",
    "        if diversity is None:\n",
    "            next_index = np.argmax(preds[len(generated) - 1])\n",
    "        else:\n",
    "            preds = np.asarray(preds[len(generated) - 1]).astype('float64')\n",
    "            preds = np.log(preds) / diversity\n",
    "            exp_preds = np.exp(preds)\n",
    "            preds = exp_preds / np.sum(exp_preds)\n",
    "            probas = np.random.multinomial(1, preds, 1)\n",
    "            next_index = np.argmax(probas)     \n",
    "        next_char = chars[next_index]\n",
    "        yield next_char\n",
    "\n",
    "        generated += next_char\n",
    "    return generated\n",
    "\n",
    "for ch in generate_output(model, training_text):\n",
    "    sys.stdout.write(ch)\n",
    "print()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v3bn5bTy3aym"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9512"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_python(rootdir):\n",
    "    matches = []\n",
    "    for root, dirnames, filenames in os.walk(rootdir):\n",
    "        for fn in filenames:\n",
    "            if fn.endswith('.py'):\n",
    "                matches.append(os.path.join(root, fn))\n",
    "\n",
    "    return matches\n",
    "#  + find_python(os.path.join(sys.executable.rsplit('/', 2)[0], 'lib'))\n",
    "srcs = find_python(random.__file__.rsplit('/', 1)[0])\n",
    "len(srcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zYoPHqHY3ayp"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this = \"\"\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def replacer(value):\n",
    "    value = ''.join(ch for ch in value if ord(ch) < 127)\n",
    "    if not ' ' in value:\n",
    "        return value\n",
    "    if sum(1 for ch in value if ch.isalpha()) > 6:\n",
    "        return 'MSG'\n",
    "    return value\n",
    "\n",
    "\n",
    "def replace_literals(st):\n",
    "    res = []\n",
    "    start_text = start_quote = i = 0\n",
    "    quote = ''\n",
    "    while i < len(st):\n",
    "        if quote:\n",
    "            if st[i: i + len(quote)] == quote:\n",
    "                quote = ''\n",
    "                start_text = i\n",
    "                res.append(replacer(st[start_quote: i]))\n",
    "        elif st[i] in '\"\\'':\n",
    "            quote = st[i]\n",
    "            if i < len(st) - 2 and st[i + 1] == st[i + 2] == quote:\n",
    "                quote = 3 * quote\n",
    "            start_quote = i + len(quote)\n",
    "            res.append(st[start_text: start_quote])\n",
    "        if st[i] == '\\n' and len(quote) == 1:\n",
    "            start_text = i\n",
    "            res.append(quote)\n",
    "            quote = ''\n",
    "        if st[i] == '\\\\':\n",
    "            i += 1\n",
    "        i += 1\n",
    "    return ''.join(res) + st[start_text:]\n",
    "\n",
    "#replace_literals('print(\"hel\\\\\"lo\")') + replace_literals(\"print('hel\\\\'lo world')\")\n",
    "replace_literals('this = \"wrong\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CWAhUnZm3ayr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not read /home/super/anaconda3/envs/ML/lib/python3.6/site-packages/IPython/core/tests/nonascii.py\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "81763474"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COMMENT_RE = re.compile('#.*')\n",
    "python_code = []\n",
    "for fn in srcs:\n",
    "    try:\n",
    "        with open(fn, 'r') as fin:\n",
    "            src = fin.read()\n",
    "    except UnicodeDecodeError:\n",
    "        print('Could not read %s' % fn)\n",
    "    src = replace_literals(src)\n",
    "    src = COMMENT_RE.sub('', src)\n",
    "    python_code.append(src)\n",
    "\n",
    "python_code = '\\n\\n\\n'.join(python_code)\n",
    "len(python_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tyi1IXsO3ayv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_chars = list(sorted(set(python_code)))\n",
    "py_char_to_idx = {ch: idx for idx, ch in enumerate(py_chars)}\n",
    "len(py_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nA6VanAV3ayz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, None, 98)          0         \n",
      "_________________________________________________________________\n",
      "lstm_layer_1 (LSTM)          (None, None, 640)         1891840   \n",
      "_________________________________________________________________\n",
      "lstm_layer_2 (LSTM)          (None, None, 640)         3279360   \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, None, 98)          62818     \n",
      "=================================================================\n",
      "Total params: 5,234,018\n",
      "Trainable params: 5,234,018\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "py_model = char_rnn_model(len(py_chars), num_layers=2, num_nodes=640, dropout=0)\n",
    "py_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TtdXhdIk3ay2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      " - 1525s - loss: 2.4727 - acc: 0.4464\n",
      "Epoch 2/40\n",
      " - 1550s - loss: 1.9531 - acc: 0.5750\n",
      "Epoch 3/40\n",
      " - 1541s - loss: 1.9239 - acc: 0.5841\n",
      "Epoch 4/40\n",
      " - 1560s - loss: 1.9033 - acc: 0.5900\n",
      "Epoch 5/40\n",
      " - 1594s - loss: 2.0104 - acc: 0.5604\n",
      "Epoch 6/40\n",
      " - 1591s - loss: 2.0587 - acc: 0.5447\n",
      "Epoch 7/40\n",
      " - 1588s - loss: 2.0388 - acc: 0.5505\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f23c0ed2e48>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early = keras.callbacks.EarlyStopping(monitor='loss',\n",
    "                              min_delta=0.03,\n",
    "                              patience=3,\n",
    "                              verbose=0, mode='auto')\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "py_model.fit_generator(\n",
    "    data_generator(python_code, py_char_to_idx, batch_size=BATCH_SIZE, chunk_size=160),\n",
    "    epochs=40,\n",
    "    callbacks=[early,],\n",
    "    steps_per_epoch=2 * len(python_code) / (BATCH_SIZE * 160),\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lKQ9LYD_3ay5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "def UTASYIGn_p viou oo  utra\n",
      "    re_resut_ri_hmal = resultity_or_flaters_emitsneed]\n",
      "r = imageed.AndOfOptr_gnuh()\n",
      "val = RootPtxINrread( elif    tmminiu\n",
      "hh=npcap ):\n",
      "    if hstate dw[\n",
      "            ipmite']''rore':\n",
      "   window_shun\n",
      "    retueepale_tt =pandli)\n",
      "f(ir = 0hrrpos(ht =losenoul - taflig _a %i, us,cr zyout, (_iw_ari,ynals))\n",
      "   executeerpchts = func_cub.omr(\"pyg =eao4)\n",
      "  non_fy_valuz = 'image' + fytGbF'\n",
      " pair = pyfi = {np\\ ' y\n",
      "       tshap moders. To. += HISTfraeou\n",
      "        ,   opti = g +if 'As i -,  H'r\"Modefisit,va: VeearCycleRestColo * ssn2[morcel',tf =o +1 /]\n",
      "        ival=onexpdefects_format * 1)\n",
      "\n",
      "\n",
      "\n",
      "def \"   uni % s  , ly r and  (refruileva compa andflk >= region) and   ] ==   default =-tt e.send_co = 1S1 *]:\n",
      "[_n+uuXpointe  \n",
      "\n",
      "\n",
      "\n",
      "def testate2_fmd(set =f ny(t + 1]):exec\n",
      "  a from @test import test_ a pU_SYS_BIND_bf=rflline_ ianSamolegoos_exe\\le .s order()\n",
      "    errorcodsnameed = pa_status_ph\n",
      "    engining=updx,\n",
      "\n",
      "\n",
      "\n",
      "def a,(a3centstat == ba + one(br2),\n",
      "      .1_ * 1, 3),  \n",
      "'(ar, :', a.outputs):\n",
      " wr5c no'arctive', _operator_plu(..zp,dattmc\n",
      "   np.7st)assert_9 mE ch, nu\n",
      "th_em().d strc =np.scalar([8, 2, irb]  \n",
      ".a)\n",
      "\n",
      "\n",
      "\n",
      "def tesi_Bdfrom   ndart50nsnode] ne 'TOL '.jog ie':T '\\nl_st'a.context_stor',teefoy(Falnameval for n i        op.names\n",
      "f import tokenc\n",
      "for i in argsTrees:\n",
      "    retudn0_roiteg_e = args[0].r=='math/trialzo'\n",
      "newmatsiz =IndexEar\n",
      " 0WidsPutswi =la\n",
      " get_source_optifier = re.compI =(n_c\n",
      "UBHOR +        **m.map.chaOps\n",
      "    req = cursor.msa_- 1\n",
      "  argind = Nonefp[m]\n",
      "\n",
      "\n",
      "\n",
      "def .doc == \"algnar af == mwds.pophandlet=0ac.type:typeI o1 C(sour pool):assig3pro  DICKT ar \" - {\n",
      "ed2: Int( DataFr a   ha = 0)\n",
      "    comment\\t4;SgtTrahtr(type.Func not , \\\n",
      " )\n",
      "else wi(float_stota_traope< =ein=Traaab\n",
      "elempr  Cal t __vl__bounl\n",
      " qqunkinPut = c=ell2  \n",
      "\n",
      "\n",
      "\n",
      "def _where_cell(key = None):\n",
      " Msg_NotPluginat = time.one(ope - nt.one)\n",
      " featuCMRDo =executor_pr\n",
      "    d = op.0\n",
      "BLXSD' a ',notchalaigh resfi dec * objeigty\n",
      "\n",
      "\n",
      "\n",
      "def ' el'i.dets':\n",
      ", _my_mc\n",
      "_VA  on] =  inequadec \n",
      "        'sunt 1 =.max\n",
      " c-':Fi)Tcopy.'rSSLHORTIAT-\n",
      "\n",
      "\n",
      "\n",
      "def ipest = ImportVurie0():\n",
      "    TeIt = rNC.token.item\"\n",
      "  1 counteror = Imaile--\"\n",
      "  def TextRol\n",
      " e):\n",
      "    \"\"\"MSG nosed/4 *.test an2 \n",
      "       mur_folo ine\n",
      "\n",
      "\n",
      "\n",
      "def test_quabab in Nsma=AnglexD1dist):\n",
      "  \n",
      "  \n",
      " (com -= c / check_exclse0 x tia\n",
      "    r=B)\n",
      " , 'Arrb =selfgi + 1.ipo +\n",
      "   )\n",
      "    raise AftoutNameE at rave , name:\n",
      "    ra = out)\n",
      "    rgasef  a <(pro4y) tnhoers test  _model`ntermi)\n",
      "\n",
      "\n",
      "\n",
      "def {'widthe 'x':framer0(n)se + '{tda :+ []i/bint]',[]listlik 'liso: ']g>9,\n",
      "        'EIe', Non = im +index +optionstuf +elr.inner\n",
      "    __vi Nright_r GINTynin, t   sys.exeeut_conument writer,rate, bkey, parre in c_me f_ if e_upe{}i ip  \n",
      "\n",
      "\n",
      "\n",
      "def i notma\n",
      "  c_inppe)\n",
      "\n",
      "\n",
      "\n",
      "def i = ke and fromtBCtlements, f'MSG'\n",
      "  return sec rhandsun_un ankw\n",
      "  for k unstnea_clusuexarrbroun, afdcda0, assert_e astd oo \"MnsVonri_g\n",
      "    else:e\n",
      "\n",
      "\n",
      "\n",
      "def tese_lstrip_factos(sipltra0, temp):\n",
      " _( p)\n",
      "\n",
      "\n",
      "\n",
      "def __lowidts__set__ GNo'\"):\n",
      "   __ops = Lise(Widg:AlignxScrees())\n",
      "sels.ra)\n",
      "\n",
      "\n",
      "\n",
      "def repeat configent\n",
      "  return confi id\n",
      "\n",
      "\n",
      "\n",
      "def a ans _bup(values, messor  'MSG',\n",
      "      typ6=1000 _):\n",
      "itlist2 = NonerLexer()\n",
      "    \n",
      "ovt=  'MSGhs'1@gr < 'Trr')\n",
      "    Doc_SPn.CCVr awixd_ae)\n",
      "  s_rightKe =trdirpacked and not seeleflown for'\n",
      "  abz_ crimeharer.addPrii  replitGrevNane  \n",
      "\n",
      "\n",
      "\n",
      "def _( (\n",
      "      Po U.C I(ir ):\n",
      "  op. = self. /left  Cd = op= au0 + 1\n",
      ",   \n",
      "    M = r \n",
      "    s = ....  \n",
      "\n",
      "\n",
      "\n",
      "def _ extency_quotes(q)\n",
      ", *Queeor n of _conee & _UNIT)\n",
      "  spa      l = urM_Spect\n",
      "Inputtrt = \n",
      "global_step_tnStr,\n",
      "  def nan_tz_repluc  = N=TimnStrategCs_COVAas timestamp_axil_bluemode:\n",
      "    lswitchN = Tr  lls else cell.position = Trne\n",
      "    trigger = Conu  . '\n",
      "    \n",
      "    CNTK,maVess_ = o \n",
      "]\n",
      "\n",
      "\n",
      "\n",
      "def _patSe not in sel\n",
      "xs3n_kind0quaxes(ketr):rep = use_loadxfalse(a_im, lower_rki  )_expatedn and   r is ex elseco\n",
      " osirmail else linewiiqudnams, stop_evrn term, al\"\n",
      "    _get = \"ad'\n",
      "    for agy_6 i =ed_str =\n",
      "        li.(\"string_aif', ax\n",
      "        snp and_adapt(1\", False  \n",
      "tees_per\n",
      "    stess and\n",
      "    0 is nwargs.ge   \n",
      "        strin\n",
      "Mont:// text[pad_am])\n",
      "self.auto_semi=\"month 53[3]  -\"ind1detnumce \\an\\0526\\\".\\snaot.IfALon = \n",
      "   =[0,%m] *rng i -orti[-10]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_code(model, start_with='\\ndef ', end_with='\\n\\n', diversity=1.0):\n",
    "    generated = start_with\n",
    "    yield generated\n",
    "    for i in range(2000):\n",
    "        x = np.zeros((1, len(generated), len(py_chars)))\n",
    "        for t, char in enumerate(generated):\n",
    "            x[0, t, py_char_to_idx[char]] = 1.\n",
    "        preds = model.predict(x, verbose=0)[0]\n",
    "        \n",
    "        preds = np.asarray(preds[len(generated) - 1]).astype('float64')\n",
    "        preds = np.log(preds) / diversity\n",
    "        exp_preds = np.exp(preds)\n",
    "        preds = exp_preds / np.sum(exp_preds)\n",
    "        probas = np.random.multinomial(1, preds, 1)\n",
    "        next_index = np.argmax(probas)        \n",
    "        next_char = py_chars[next_index]\n",
    "        yield next_char\n",
    "\n",
    "        generated += next_char\n",
    "        if generated.endswith(end_with):\n",
    "            break\n",
    "st = ''\n",
    "for i in range(20):\n",
    "    for ch in generate_code(py_model):\n",
    "        sys.stdout.write(ch)\n",
    "        st += ch\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4aXCikNh3ay7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      " - 489s - loss: 2.7627 - acc: 0.3772\n",
      "Epoch 2/40\n",
      " - 497s - loss: 2.0918 - acc: 0.5375\n",
      "Epoch 3/40\n",
      " - 504s - loss: 2.0394 - acc: 0.5520\n",
      "Epoch 4/40\n",
      " - 499s - loss: 2.0445 - acc: 0.5522\n",
      "Epoch 5/40\n",
      " - 496s - loss: 2.0073 - acc: 0.5614\n",
      "Epoch 6/40\n",
      " - 500s - loss: 2.0350 - acc: 0.5543\n",
      "Epoch 7/40\n",
      " - 498s - loss: 2.0334 - acc: 0.5544\n",
      "Epoch 8/40\n",
      " - 496s - loss: 2.0398 - acc: 0.5531\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f23ba8c8a90>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 512\n",
    "\n",
    "flat_model = char_rnn_model(len(py_chars), num_layers=1, num_nodes=512, dropout=0)\n",
    "\n",
    "early = keras.callbacks.EarlyStopping(monitor='loss',\n",
    "                              min_delta=0.03,\n",
    "                              patience=3,\n",
    "                              verbose=0, mode='auto')\n",
    "\n",
    "flat_model.fit_generator(\n",
    "    data_generator(python_code, py_char_to_idx, batch_size=BATCH_SIZE, chunk_size=160),\n",
    "    epochs=40,\n",
    "    callbacks=[early,],\n",
    "    steps_per_epoch=2 * len(python_code) / (BATCH_SIZE * 160),\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nt_fTNfv3ay9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33, 512)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_code = 'if a == 2:\\n    b=1\\nelse:\\n    b=2\\n'\n",
    "#example_code = 'a=(2 * 3)\\nb=(4 * 6 + 7)\\nreturn C'\n",
    "\n",
    "def activations(model, code):\n",
    "    x = np.zeros((1, len(code), len(py_char_to_idx)))\n",
    "    for t, char in enumerate(code):\n",
    "        x[0, t, py_char_to_idx[char]] = 1.\n",
    "    output = model.get_layer('lstm_layer_1').output\n",
    "    f = K.function([model.input], [output])\n",
    "    return f([x])[0][0]\n",
    "\n",
    "act = activations(flat_model, example_code)\n",
    "act.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oUXD8JDI3ay-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def interesting_neurons(act):\n",
    "    res = []\n",
    "    for n in np.argmax(act, axis=1):\n",
    "        if not n in res:\n",
    "            res.append(n)\n",
    "    return res\n",
    "\n",
    "neurons = interesting_neurons(act)\n",
    "len(neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mh2pwk-Z3azA"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAAkCAIAAAAVY5oqAAACbElEQVR4nO3bMU4bQRjF8d1gQCRypNBBoIiUNEScIkegSEOTk4z3JDRIqXKCHAORJkgpIKFzJBAgQBEURtYCYt+H52P5sv7/OqTHeHdn9nlsecvBYFAAQFQvnvsAAKBJr/5HSqkoiqqqGv5hlJGx7pnyE/c6a9/Rml9lZNrmy4vjTGXeO7d2UlVVWRpKxrqnPmH1GwB2KaXWLt0ULtGw8u+dXn2gkYdmd5zJr1iXXcmjjjnztVjxzZNuuc6OFe+1q33UEprONeA17znK+hfnsn1cdoDjQdrZ+Ttq5/pE4ztfXu9wluMx3mCWESxDMe+W0Sb4356OeBuddv47aps7qcJ2lTu2TO3a/w4of/2Mbz9j2TUPlXkw/ynjvGfW3DOU1J2GnpjlnN2/7u3ke2a+9i+IyyvWP4GmlJ7uA0tXWa5M/r1z83Hvfl/cH+tOZuKZs7xWNMZz72SFee2SHOddHpLjerZv2Jl3Oc5kQ5X8mBNAZPyYE0BolBSA0HpfP+vQly2d6R/rzLcNndnc1pm/b3Tm5anOXMzpzN57nVkc6szZgs68/a0zw0WduSp1Zu5CZ5b/6MzJK53ZX9WZ8kpnjl7rzIefOnPc15mlQ53Z/agz/2Z0Zu2HzlzO6syvdzpjWWOWe/l8XmcOVnTGMu/spACERkkBCI2SAhAaJQUgNEoKQGiUFIDQKCkAoVFSAEKjpACERkkBCI2SAhBa+en7QIZ21vVAlmd5LM+vWZ5Rsjybhu6ZvdQZy/pBS5zuU3ZSAEKjpACERkkBCI2SAhAaJQUgNEoKQGiUFIDQKCkAoVFSAEKjpACERkkBCO0apxUu7CH/004AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_neurons(neurons, code, act, cell_size=12):\n",
    "    img = np.full((len(neurons) + 1, len(code), 3), 128)\n",
    "    scores = (act[:, neurons].T + 1) / 2\n",
    "    img[1:, :, 0] = 255 * (1 - scores)\n",
    "    img[1:, :, 1] = 255 * scores\n",
    "    \n",
    "\n",
    "    f = BytesIO()\n",
    "    #img = scipy.misc.imresize(img, float(cell_size), interp='nearest')\n",
    "    pil_img = PIL.Image.fromarray(np.uint8(img))\n",
    "    pil_img = pil_img.resize((pil_img.size[0]*cell_size, pil_img.size[1]*cell_size), PIL.Image.NEAREST)\n",
    "    draw = ImageDraw.Draw(pil_img)\n",
    "    for idx, ch in enumerate(code):\n",
    "        draw.text((idx * cell_size + 2, 0), ch)\n",
    "    pil_img.save(f, 'png')\n",
    "    return Image(data=f.getvalue())\n",
    "\n",
    "img = visualize_neurons(neurons, example_code, act)\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BR6lL2qY3azC"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbwAAAAkCAIAAAB9kBgSAAAC3ElEQVR4nO3bPWsUURTG8dk4EITEQiWVYKciiIWNYGnlJ7AQCz/J7HwSiyB+BAtrwcZCBFE7wSqohREkEF+KxWF2k8xzzt6zd+8s/1+bZ+e+nLln11l3Mp1OKwCAzda6JwAAYzLXNJumaZpm+AXNf+ljh1ykKJbNKXDVmWs6kImaRn5jrLtROTOPOl+JK5prmm3btm0rB5Mxi6Zp0i9SlG5zqsGqtG1bzl04E1UIS003su6WghZYd4ty6hV4vhJrUfcn1F3x1GiX6c9+Oa53g6iB5LoSx3K9Nv1elPszG0IWK+okB77Dx95geepuX1qGulfzfWHpEUPOaVQtws/X0rWo+xMa3iPLCYzSL3zKfWZ5Yexy8myRcX+6vnlW5uQBK8EY656Hpe7dX6vVV9Y4H3kdey3yt6CTf6pXPfZy+oVPkfMTR5WxolH7s6ky171Ms0XlWZrxnzKJtch2voZHKbRpRr1P5vzEsTDnlZa2zE+I5djUT5rFGrjno2qR83wN2+om1H9keepRlAE744IXnqKOgnGqISVP35+FxzIp+xzYp9Z+KlwsZ6eTuKh+vYzfPaQPlzifWIHnS37pfdZYkzX+5/b0h+JjtNmrXukD+FEb76rHNfMMd+A6myYAjA6/CAIAh/r5Qx168lRndg915mBPZ17d05lHz3Tm547ObB/pzLHhq7IPN3Tm2yWdefBCZ/Yf68ydNzpTH+vMhR86c7irMxZ7Bzrz+5zO/J3ojGVdlrHe39SZ7xd15u5rnfl4XWcs9/O1Tzrz+arOWM7FlS86E7XPv87rzNfLOnP7rc7wSRMAHGiaAOBA0wQAB5omADjQNAHAgaYJAA40TQBwoGkCgANNEwAcaJoA4EDTBACHyf2XUxl6d0tf6GhbZyy/U/5DG988ht+DA2NBiwIAB5omADjQNAHAgaYJAA40TQBwoGkCgANNEwAcaJoA4EDTBAAHmiYAONA0AcDhHyvivO/BfvDhAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def image_for_code(code):\n",
    "    act = activations(flat_model, code)\n",
    "    neurons = interesting_neurons(act)\n",
    "    return visualize_neurons(neurons, code, act)\n",
    "\n",
    "display(image_for_code('if (a == 2) and ((b == 1) or (c==2)):'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HWcagIrR3azF"
   },
   "outputs": [],
   "source": [
    "code = 'if (a == 2) and ((b == 1) or (c==2)):'\n",
    "mask = '   ________     ____________________ '\n",
    "act = activations(flat_model, code)\n",
    "positive = [idx for idx, ch in enumerate(mask) if ch == '_']\n",
    "negative = [idx for idx, ch in enumerate(mask) if ch != '_']\n",
    "\n",
    "neurons = np.argsort(act[positive].sum(axis=0) - act[negative].sum(axis=0))[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SO9Uey363azG"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbwAAABICAIAAAACptczAAAEoklEQVR4nO3d34tUdRzG8Zl11EhFVjORFIT0TgOjm4zSq9QIvDL8azpz/pvIK0FY7UqL7CYSsju9ECrETBdRwx/perE4zK46z/PZ89nvnLO+X7f77Pn1me8z46xnpj8cDnsAAM/MtA8AALpkSWlWVVVV1eRfqF5qvu+UjbSKc3FaeNaFZzohk3UY5XVx7qb2HHnW+mp4RktKs67ruq7lzmTMUVVV8420yuji9CZOpa7r9jwKF2UNwpnpmpy7M9AWzt3Rnnklrq+GsxiMH9Boi6+NjjLjR78yoWeDrB3J82q4r9DvNn8syuuzuAs5rKyVnPgMn/sAKzN3/9QKzL23tBdWvMeUdZo1i/T1teJZDMYPaPI1clZglvHBN3mcOb+YezplLpF5fUa9+abMqwusDbo49zKcuY9+2lv9yZrHI7fjz6J8Bb36o8Fq73tlxgffRMlXHL2CE826PmtV4bm30+JJlTk1858yDWdRbH1N3ktLSzPrebLkK45lx7yqo23nK8T2WKuvNFtrwmM+axYl19dkM6MDGn/L8rVLUQZ85gkvexe1E8xDTRl58+uz7G2ZJtc5saemvipCnLUz0vCkxudl/u2h+e4aHk+uxPUl/+j9pn31p/if25u/Kd5Fa/usV/UN+E7r7ll368gLPAKnWZoA0DncEQQAAYMPr+nQ9X06MzuvM/OzOpPlwjGd+eJHnbm3VWe239GZZ+t0Zua5zmx4ojNdtNDXmcH/OvPdaZ05fl5nHm7SGWfu/QWdcc6rpKfrdcaZ191tOvP3Bzpz8KrOONfZWV/rnhnb0REAwEuUJgAEUJoAEEBpAkAApQkAAZQmAARQmgAQQGkCQAClCQABlCYABFCaABAwuLZfh5z7On/6XGdu7dSZoxd1xrmP+9gFnXH88KXOnDyrM+uf6sx/7+qMc++5c32cmV46krMd57yOXMrZ16kzOuOYO6Ez33yfsy/n8w223tMZZ+7nvtaZHbd15vBlnflrt87svaEzJT9v4eYuneGVJgAEUJoAEEBpAkAApQkAAZQmAARQmgAQQGkCQAClCQABlCYABFCaABBAaQJAQP/b4VCHjHt+S7p6UGec70p2ON/d7FyfG3t1xrk//cAfOuNwvtv6wWadcb7vPsuVQzpz6ErOvpz7pt95pDO/fqIzW+7rzGc/64zD+fyHnbd05vFGndn4WGcc87M6c/Fozr5OzOkMrzQBIIDSBIAAShMAAihNAAigNAEggNIEgABKEwACKE0ACKA0ASCA0gSAAEoTAAIGC/2cDTnbcb7f2bkPd9/1nONx7r9+bjytbLurMx/9rjMl7/F37nPf9FBnnHvz/3lfZ977V2f2/Kkzt3fojMP5/mvncfjxbzqTdY+2w/kMBOfcd93M2c6TDTrjrJ1Pf9GZ7Xd0xlkXvNIEgABKEwACKE0ACKA0ASCA0gSAAEoTAAIoTQAIoDQBIIDSBIAAShMAAihNAAgYXD6sQ873jDvfg3x/i84493qjY5I+3wBvp7mvpn0ES1FRABBAaQJAAKUJAAGUJgAEUJoAEEBpAkAApQkAAZQmAARQmgAQQGkCQAClCQABLwAZPw5NCdEOZQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = visualize_neurons(neurons, code, act)\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jkkrYn1O3azI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 44,   0, 222, 454, 501])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ty2yBySh3azK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09292999"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act[negative, 108].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vwu-uQFW3azM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.006925315210537519, 0.09292998909950256)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0 = 0\n",
    "x1 = 0\n",
    "for idx, ch in enumerate(mask):\n",
    "    if ch == '_':\n",
    "        x0 += act[idx, 108]\n",
    "    else:\n",
    "        x1 += act[idx, 108]\n",
    "x0, x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kft-cxL23azP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "05.1 Generating Text in the Style of an Example Text.ipynb의 사본",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
